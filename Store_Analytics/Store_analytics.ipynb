{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbdd9abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skimage\n",
      "  Using cached skimage-0.0.tar.gz (757 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [3 lines of output]\n",
      "  \n",
      "  *** Please install the `scikit-image` package (instead of `skimage`) ***\n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c5cd6e",
   "metadata": {},
   "source": [
    "# 1st Version | Working Version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734cd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Tracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 35:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "#                    print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0b9be82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 24 persons, 183.1ms\n",
      "Speed: 1.0ms preprocess, 183.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[993, 1]\n",
      "[406, 237]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 320x640 25 persons, 208.5ms\n",
      "Speed: 1.0ms preprocess, 208.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[712, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 320x640 22 persons, 197.5ms\n",
      "Speed: 0.5ms preprocess, 197.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[797, 15]\n",
      "[797, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 320x640 17 persons, 202.3ms\n",
      "Speed: 1.0ms preprocess, 202.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 15 persons, 195.3ms\n",
      "Speed: 1.0ms preprocess, 195.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 21 persons, 195.8ms\n",
      "Speed: 0.0ms preprocess, 195.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 19 persons, 215.4ms\n",
      "Speed: 1.0ms preprocess, 215.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 18 persons, 1 train, 266.2ms\n",
      "Speed: 0.0ms preprocess, 266.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 20 persons, 261.4ms\n",
      "Speed: 1.9ms preprocess, 261.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 18 persons, 233.3ms\n",
      "Speed: 1.0ms preprocess, 233.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 19 persons, 258.9ms\n",
      "Speed: 1.0ms preprocess, 258.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 20 persons, 262.4ms\n",
      "Speed: 1.0ms preprocess, 262.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 16 persons, 1 teddy bear, 383.8ms\n",
      "Speed: 1.0ms preprocess, 383.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 20 persons, 220.0ms\n",
      "Speed: 1.0ms preprocess, 220.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 23 persons, 194.6ms\n",
      "Speed: 1.0ms preprocess, 194.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 22 persons, 198.9ms\n",
      "Speed: 0.0ms preprocess, 198.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 20 persons, 197.2ms\n",
      "Speed: 1.0ms preprocess, 197.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 207.8ms\n",
      "Speed: 1.0ms preprocess, 207.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 22 persons, 200.6ms\n",
      "Speed: 1.0ms preprocess, 200.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 20 persons, 197.7ms\n",
      "Speed: 1.2ms preprocess, 197.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 19 persons, 196.7ms\n",
      "Speed: 1.3ms preprocess, 196.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 19 persons, 203.1ms\n",
      "Speed: 1.0ms preprocess, 203.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 23 persons, 215.2ms\n",
      "Speed: 2.0ms preprocess, 215.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 23 persons, 196.4ms\n",
      "Speed: 1.0ms preprocess, 196.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 190.3ms\n",
      "Speed: 0.0ms preprocess, 190.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 22 persons, 231.6ms\n",
      "Speed: 1.0ms preprocess, 231.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 23 persons, 203.1ms\n",
      "Speed: 1.0ms preprocess, 203.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 262.1ms\n",
      "Speed: 1.0ms preprocess, 262.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 21 persons, 202.3ms\n",
      "Speed: 1.0ms preprocess, 202.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 208.8ms\n",
      "Speed: 0.0ms preprocess, 208.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 204.9ms\n",
      "Speed: 0.0ms preprocess, 204.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 203.7ms\n",
      "Speed: 1.5ms preprocess, 203.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 195.9ms\n",
      "Speed: 1.0ms preprocess, 195.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 196.8ms\n",
      "Speed: 1.0ms preprocess, 196.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 195.6ms\n",
      "Speed: 1.0ms preprocess, 195.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 198.4ms\n",
      "Speed: 0.0ms preprocess, 198.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 214.6ms\n",
      "Speed: 7.0ms preprocess, 214.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 195.8ms\n",
      "Speed: 1.0ms preprocess, 195.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 217.7ms\n",
      "Speed: 0.0ms preprocess, 217.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 206.9ms\n",
      "Speed: 0.0ms preprocess, 206.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 suitcase, 229.1ms\n",
      "Speed: 1.1ms preprocess, 229.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 268.4ms\n",
      "Speed: 0.0ms preprocess, 268.4ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 279.1ms\n",
      "Speed: 2.0ms preprocess, 279.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 318.9ms\n",
      "Speed: 2.0ms preprocess, 318.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 218.8ms\n",
      "Speed: 2.0ms preprocess, 218.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 183.4ms\n",
      "Speed: 1.0ms preprocess, 183.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 199.6ms\n",
      "Speed: 1.0ms preprocess, 199.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 200.7ms\n",
      "Speed: 1.0ms preprocess, 200.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[586, 491]\n",
      "[582, 476]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 320x640 28 persons, 190.2ms\n",
      "Speed: 1.0ms preprocess, 190.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[511, 285]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 320x640 28 persons, 179.7ms\n",
      "Speed: 1.0ms preprocess, 179.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 173.6ms\n",
      "Speed: 1.0ms preprocess, 173.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 truck, 187.2ms\n",
      "Speed: 1.0ms preprocess, 187.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 32 persons, 192.7ms\n",
      "Speed: 1.0ms preprocess, 192.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 180.7ms\n",
      "Speed: 1.1ms preprocess, 180.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 195.2ms\n",
      "Speed: 1.0ms preprocess, 195.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 33 persons, 188.1ms\n",
      "Speed: 1.0ms preprocess, 188.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[742, 130]\n",
      "[742, 124]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 320x640 25 persons, 194.0ms\n",
      "Speed: 0.0ms preprocess, 194.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[755, 46]\n",
      "[758, 38]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 320x640 27 persons, 192.1ms\n",
      "Speed: 0.0ms preprocess, 192.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 2 bicycles, 188.2ms\n",
      "Speed: 0.5ms preprocess, 188.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 2 bicycles, 189.6ms\n",
      "Speed: 1.0ms preprocess, 189.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 bicycle, 186.4ms\n",
      "Speed: 0.5ms preprocess, 186.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 1 truck, 190.9ms\n",
      "Speed: 0.0ms preprocess, 190.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 truck, 182.2ms\n",
      "Speed: 1.0ms preprocess, 182.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 32 persons, 1 bicycle, 1 truck, 238.5ms\n",
      "Speed: 2.0ms preprocess, 238.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 200.2ms\n",
      "Speed: 0.0ms preprocess, 200.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 31 persons, 186.4ms\n",
      "Speed: 0.0ms preprocess, 186.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 33 persons, 1 bicycle, 1 truck, 191.7ms\n",
      "Speed: 1.0ms preprocess, 191.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 bicycle, 193.2ms\n",
      "Speed: 0.0ms preprocess, 193.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 31 persons, 1 bicycle, 189.8ms\n",
      "Speed: 1.1ms preprocess, 189.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 2 bicycles, 190.1ms\n",
      "Speed: 1.0ms preprocess, 190.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 34 persons, 1 bicycle, 205.6ms\n",
      "Speed: 1.0ms preprocess, 205.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 31 persons, 1 bicycle, 207.6ms\n",
      "Speed: 1.0ms preprocess, 207.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 2 bicycles, 230.9ms\n",
      "Speed: 2.0ms preprocess, 230.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 1 bicycle, 201.5ms\n",
      "Speed: 1.0ms preprocess, 201.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 33 persons, 1 bicycle, 1 handbag, 191.3ms\n",
      "Speed: 1.0ms preprocess, 191.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 34 persons, 1 bicycle, 182.3ms\n",
      "Speed: 0.5ms preprocess, 182.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 32 persons, 2 bicycles, 196.0ms\n",
      "Speed: 1.0ms preprocess, 196.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 32 persons, 2 bicycles, 194.2ms\n",
      "Speed: 1.4ms preprocess, 194.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 31 persons, 3 bicycles, 202.2ms\n",
      "Speed: 0.0ms preprocess, 202.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 34 persons, 1 bicycle, 200.2ms\n",
      "Speed: 1.0ms preprocess, 200.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 2 bicycles, 188.8ms\n",
      "Speed: 1.0ms preprocess, 188.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 1 bicycle, 187.0ms\n",
      "Speed: 1.0ms preprocess, 187.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 31 persons, 2 bicycles, 209.5ms\n",
      "Speed: 1.0ms preprocess, 209.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 2 bicycles, 212.3ms\n",
      "Speed: 1.0ms preprocess, 212.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 36 persons, 193.3ms\n",
      "Speed: 1.3ms preprocess, 193.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 1 bicycle, 198.4ms\n",
      "Speed: 1.0ms preprocess, 198.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 2 bicycles, 186.1ms\n",
      "Speed: 1.0ms preprocess, 186.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 2 bicycles, 182.7ms\n",
      "Speed: 1.0ms preprocess, 182.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 2 bicycles, 190.2ms\n",
      "Speed: 0.0ms preprocess, 190.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 2 bicycles, 188.5ms\n",
      "Speed: 0.0ms preprocess, 188.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 1 bicycle, 196.4ms\n",
      "Speed: 0.0ms preprocess, 196.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 2 bicycles, 193.4ms\n",
      "Speed: 0.0ms preprocess, 193.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 31 persons, 1 bicycle, 1 suitcase, 205.9ms\n",
      "Speed: 0.5ms preprocess, 205.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 31 persons, 2 bicycles, 1 suitcase, 213.2ms\n",
      "Speed: 0.0ms preprocess, 213.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 bicycle, 199.6ms\n",
      "Speed: 1.0ms preprocess, 199.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 1 skateboard, 201.6ms\n",
      "Speed: 0.0ms preprocess, 201.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 bicycle, 220.4ms\n",
      "Speed: 1.0ms preprocess, 220.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 33 persons, 1 bicycle, 204.4ms\n",
      "Speed: 2.0ms preprocess, 204.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 33 persons, 1 bicycle, 198.1ms\n",
      "Speed: 1.0ms preprocess, 198.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 33 persons, 1 bicycle, 1 suitcase, 189.5ms\n",
      "Speed: 1.0ms preprocess, 189.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 204.6ms\n",
      "Speed: 1.6ms preprocess, 204.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 213.2ms\n",
      "Speed: 1.0ms preprocess, 213.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 34 persons, 1 bicycle, 211.5ms\n",
      "Speed: 1.0ms preprocess, 211.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[643, 345]\n",
      "[654, 332]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 320x640 34 persons, 1 bicycle, 184.9ms\n",
      "Speed: 1.0ms preprocess, 184.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[696, 277]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 320x640 28 persons, 2 bicycles, 191.0ms\n",
      "Speed: 1.0ms preprocess, 191.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 32 persons, 1 bicycle, 193.5ms\n",
      "Speed: 0.0ms preprocess, 193.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[935, 0]\n",
      "[935, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 320x640 27 persons, 1 bicycle, 187.2ms\n",
      "Speed: 0.0ms preprocess, 187.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 bicycle, 197.5ms\n",
      "Speed: 0.0ms preprocess, 197.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 31 persons, 1 bicycle, 180.6ms\n",
      "Speed: 1.0ms preprocess, 180.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 191.7ms\n",
      "Speed: 1.0ms preprocess, 191.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 200.7ms\n",
      "Speed: 2.0ms preprocess, 200.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 1 bicycle, 200.7ms\n",
      "Speed: 1.0ms preprocess, 200.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 228.6ms\n",
      "Speed: 1.3ms preprocess, 228.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 bicycle, 210.5ms\n",
      "Speed: 0.5ms preprocess, 210.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 199.0ms\n",
      "Speed: 0.0ms preprocess, 199.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 195.1ms\n",
      "Speed: 1.6ms preprocess, 195.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 190.7ms\n",
      "Speed: 1.3ms preprocess, 190.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 237.3ms\n",
      "Speed: 1.0ms preprocess, 237.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 356.1ms\n",
      "Speed: 16.0ms preprocess, 356.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 431.0ms\n",
      "Speed: 3.0ms preprocess, 431.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 1 bicycle, 342.4ms\n",
      "Speed: 3.0ms preprocess, 342.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 1 bicycle, 325.9ms\n",
      "Speed: 2.0ms preprocess, 325.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 1 bicycle, 281.2ms\n",
      "Speed: 2.0ms preprocess, 281.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 1 bicycle, 320.3ms\n",
      "Speed: 2.1ms preprocess, 320.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 201.5ms\n",
      "Speed: 1.7ms preprocess, 201.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 197.7ms\n",
      "Speed: 1.4ms preprocess, 197.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 32 persons, 1 bicycle, 446.5ms\n",
      "Speed: 1.0ms preprocess, 446.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 306.9ms\n",
      "Speed: 2.0ms preprocess, 306.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 1 bicycle, 274.1ms\n",
      "Speed: 1.0ms preprocess, 274.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 1 bicycle, 286.8ms\n",
      "Speed: 1.5ms preprocess, 286.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 31 persons, 1 bicycle, 286.3ms\n",
      "Speed: 2.0ms preprocess, 286.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 1 bicycle, 1 suitcase, 331.1ms\n",
      "Speed: 1.0ms preprocess, 331.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 1 bicycle, 1 handbag, 260.1ms\n",
      "Speed: 2.0ms preprocess, 260.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 31 persons, 1 bicycle, 288.4ms\n",
      "Speed: 1.0ms preprocess, 288.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 1 bicycle, 317.6ms\n",
      "Speed: 1.0ms preprocess, 317.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 319.5ms\n",
      "Speed: 2.0ms preprocess, 319.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 bicycle, 373.6ms\n",
      "Speed: 3.0ms preprocess, 373.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 255.7ms\n",
      "Speed: 2.0ms preprocess, 255.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 20 persons, 1 bicycle, 276.4ms\n",
      "Speed: 1.9ms preprocess, 276.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 1 bicycle, 276.0ms\n",
      "Speed: 2.0ms preprocess, 276.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 258.4ms\n",
      "Speed: 1.0ms preprocess, 258.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 289.0ms\n",
      "Speed: 2.0ms preprocess, 289.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 23 persons, 1 bicycle, 1 bird, 284.0ms\n",
      "Speed: 1.0ms preprocess, 284.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 23 persons, 1 bird, 200.3ms\n",
      "Speed: 1.0ms preprocess, 200.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 1 bicycle, 192.1ms\n",
      "Speed: 1.0ms preprocess, 192.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 220.1ms\n",
      "Speed: 0.0ms preprocess, 220.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 353.7ms\n",
      "Speed: 1.0ms preprocess, 353.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 342.4ms\n",
      "Speed: 1.1ms preprocess, 342.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 20 persons, 1 bicycle, 392.1ms\n",
      "Speed: 1.3ms preprocess, 392.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 334.0ms\n",
      "Speed: 1.0ms preprocess, 334.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 294.9ms\n",
      "Speed: 1.0ms preprocess, 294.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 311.9ms\n",
      "Speed: 2.0ms preprocess, 311.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 278.1ms\n",
      "Speed: 2.0ms preprocess, 278.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 301.4ms\n",
      "Speed: 2.0ms preprocess, 301.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 271.1ms\n",
      "Speed: 0.5ms preprocess, 271.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 1 bicycle, 343.5ms\n",
      "Speed: 5.0ms preprocess, 343.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 357.8ms\n",
      "Speed: 1.0ms preprocess, 357.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 1 bicycle, 336.4ms\n",
      "Speed: 1.0ms preprocess, 336.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 353.7ms\n",
      "Speed: 3.0ms preprocess, 353.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 1 bicycle, 328.9ms\n",
      "Speed: 1.1ms preprocess, 328.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 433.9ms\n",
      "Speed: 5.0ms preprocess, 433.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 390.6ms\n",
      "Speed: 3.0ms preprocess, 390.6ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 326.8ms\n",
      "Speed: 4.0ms preprocess, 326.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 249.0ms\n",
      "Speed: 3.0ms preprocess, 249.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 235.9ms\n",
      "Speed: 1.0ms preprocess, 235.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 245.5ms\n",
      "Speed: 0.0ms preprocess, 245.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 252.0ms\n",
      "Speed: 2.1ms preprocess, 252.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 1 bicycle, 240.0ms\n",
      "Speed: 1.0ms preprocess, 240.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 222.2ms\n",
      "Speed: 1.0ms preprocess, 222.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 240.5ms\n",
      "Speed: 2.4ms preprocess, 240.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 240.8ms\n",
      "Speed: 1.6ms preprocess, 240.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 242.0ms\n",
      "Speed: 1.0ms preprocess, 242.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 233.8ms\n",
      "Speed: 1.8ms preprocess, 233.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 237.0ms\n",
      "Speed: 0.9ms preprocess, 237.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 291.0ms\n",
      "Speed: 2.0ms preprocess, 291.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 28 persons, 237.7ms\n",
      "Speed: 1.0ms preprocess, 237.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 216.8ms\n",
      "Speed: 1.0ms preprocess, 216.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 195.8ms\n",
      "Speed: 2.0ms preprocess, 195.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 1 bird, 200.6ms\n",
      "Speed: 1.0ms preprocess, 200.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 1 bird, 192.3ms\n",
      "Speed: 1.0ms preprocess, 192.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 188.8ms\n",
      "Speed: 1.1ms preprocess, 188.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 195.3ms\n",
      "Speed: 1.3ms preprocess, 195.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 1 truck, 191.3ms\n",
      "Speed: 1.0ms preprocess, 191.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 221.7ms\n",
      "Speed: 1.0ms preprocess, 221.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 197.5ms\n",
      "Speed: 1.0ms preprocess, 197.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 195.7ms\n",
      "Speed: 0.0ms preprocess, 195.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 218.8ms\n",
      "Speed: 1.1ms preprocess, 218.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 22 persons, 198.3ms\n",
      "Speed: 1.0ms preprocess, 198.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 22 persons, 195.9ms\n",
      "Speed: 0.0ms preprocess, 195.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 193.4ms\n",
      "Speed: 1.2ms preprocess, 193.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 194.5ms\n",
      "Speed: 1.0ms preprocess, 194.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 194.6ms\n",
      "Speed: 0.0ms preprocess, 194.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 23 persons, 203.8ms\n",
      "Speed: 1.0ms preprocess, 203.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 202.3ms\n",
      "Speed: 0.0ms preprocess, 202.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 22 persons, 191.8ms\n",
      "Speed: 1.0ms preprocess, 191.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 195.6ms\n",
      "Speed: 1.0ms preprocess, 195.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 21 persons, 198.5ms\n",
      "Speed: 2.0ms preprocess, 198.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 23 persons, 204.7ms\n",
      "Speed: 0.5ms preprocess, 204.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 1 bicycle, 1 truck, 218.8ms\n",
      "Speed: 1.0ms preprocess, 218.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 1 truck, 202.0ms\n",
      "Speed: 1.0ms preprocess, 202.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 1 bicycle, 195.3ms\n",
      "Speed: 0.0ms preprocess, 195.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 25 persons, 191.4ms\n",
      "Speed: 1.0ms preprocess, 191.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 24 persons, 201.3ms\n",
      "Speed: 1.0ms preprocess, 201.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 26 persons, 195.6ms\n",
      "Speed: 1.0ms preprocess, 195.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 27 persons, 188.2ms\n",
      "Speed: 0.0ms preprocess, 188.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 189.2ms\n",
      "Speed: 1.0ms preprocess, 189.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 185.9ms\n",
      "Speed: 0.0ms preprocess, 185.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 29 persons, 194.1ms\n",
      "Speed: 1.4ms preprocess, 194.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 30 persons, 192.6ms\n",
      "Speed: 1.0ms preprocess, 192.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 21 persons, 182.0ms\n",
      "Speed: 1.0ms preprocess, 182.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tracker import *\n",
    "\n",
    "\n",
    "model=YOLO('yolov8s.pt')\n",
    "\n",
    "\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        colorsBGR = [x, y]\n",
    "        print(colorsBGR)\n",
    "        \n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "cap=cv2.VideoCapture(r\"C:\\Users\\abdul\\Desktop\\peoplecount2.mp4\")\n",
    "\n",
    "\n",
    "my_file = open(\"coco.txt\", \"r\")\n",
    "data = my_file.read()\n",
    "class_list = data.split(\"\\n\")\n",
    "#print(class_list)\n",
    "count=0\n",
    "tracker=Tracker()   \n",
    "\n",
    "          #dl           #dr          #ul        #ur  \n",
    "area1 = [(180, 284), (294, 266,), (313, 291), (197, 311)]\n",
    "\n",
    "area2= [(483, 264), (390, 285), (361, 261), (476, 244)]\n",
    "\n",
    "area1_c = set()\n",
    "area2_c = set()\n",
    "\n",
    "while True:    \n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    if count % 3 != 0:\n",
    "        continue\n",
    "\n",
    "\n",
    "    frame=cv2.resize(frame,(1020,500))\n",
    "\n",
    "    results=model.predict(frame)\n",
    " #   print(results)\n",
    "    a=results[0].boxes.boxes\n",
    "    px=pd.DataFrame(a).astype(\"float\")\n",
    "#    print(px)\n",
    "    list=[]\n",
    "    for index,row in px.iterrows():\n",
    "#        print(row)\n",
    " \n",
    "        x1=int(row[0])\n",
    "        y1=int(row[1])\n",
    "        x2=int(row[2])\n",
    "        y2=int(row[3])\n",
    "        d=int(row[5])\n",
    "        c=class_list[d]\n",
    "        list.append([x1,y1,x2,y2])\n",
    "            \n",
    "    bbox_idx=tracker.update(list)\n",
    "    for bbox in bbox_idx:\n",
    "        x3,y3,x4,y4,id=bbox\n",
    "        cx=int(x3+x4)//2\n",
    "        cy=int(y3+y4)//2\n",
    "        results = cv2.pointPolygonTest(np.array(area1, np.int32),(x4,y4),False)\n",
    "        if results >=0:\n",
    "            cv2.rectangle(frame,(x3,y3),(x4,y4),(0,255,0),2)\n",
    "            cv2.circle(frame,(x4,y4),5,(255,0,255),-1)\n",
    "            cv2.putText(frame,str(int(id)),(x3,y3),cv2.FONT_HERSHEY_COMPLEX,0.5,(255,0,0),1)\n",
    "            area1_c.add(id)\n",
    "        results1 = cv2.pointPolygonTest(np.array(area2, np.int32),(x4,y4),False)\n",
    "        if results1 >=0:\n",
    "            cv2.rectangle(frame,(x3,y3),(x4,y4),(0,255,0),2)\n",
    "            cv2.circle(frame,(x4,y4),5,(255,0,255),-1)\n",
    "            cv2.putText(frame,str(int(id)),(x3,y3),cv2.FONT_HERSHEY_COMPLEX,0.5,(255,0,0),1)\n",
    "            area2_c.add(id)\n",
    "            \n",
    "    up = ('UP' ,  len(area1_c))\n",
    "    down = ('DOWN' , len(area2_c))\n",
    "    \n",
    "    cv2.putText(frame,str(up),(50,80),cv2.FONT_HERSHEY_PLAIN,3,(255,255,255),1)\n",
    "    cv2.putText(frame,str(down),(50,160),cv2.FONT_HERSHEY_PLAIN,3,(255,255,255),1)\n",
    "    \n",
    "    \n",
    "    cv2.polylines(frame, [np.array(area1, np.int32)], True, (0, 0, 225), 2)\n",
    "    cv2.polylines(frame, [np.array(area2, np.int32)], True, (0, 0, 225), 2)  \n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    \n",
    "    # Define key function to exit program by pressing 'q'\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "    if cv2.waitKey(1)&0xFF==27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab80b1",
   "metadata": {},
   "source": [
    "# 2nd Working Project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac660104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import time\n",
    "\n",
    "class MyPerson:\n",
    "    tracks = []\n",
    "    def __init__(self, i, xi, yi, max_age):\n",
    "        self.i = i\n",
    "        self.x = xi\n",
    "        self.y = yi\n",
    "        self.tracks = []\n",
    "        self.R = randint(0,255)\n",
    "        self.G = randint(0,255)\n",
    "        self.B = randint(0,255)\n",
    "        self.done = False\n",
    "        self.state = '0'\n",
    "        self.age = 0\n",
    "        self.max_age = max_age\n",
    "        self.dir = None\n",
    "    def getRGB(self):\n",
    "        return (self.R,self.G,self.B)\n",
    "    def getTracks(self):\n",
    "        return self.tracks\n",
    "    def getId(self):\n",
    "        return self.i\n",
    "    def getState(self):\n",
    "        return self.state\n",
    "    def getDir(self):\n",
    "        return self.dir\n",
    "    def getX(self):\n",
    "        return self.x\n",
    "    def getY(self):\n",
    "        return self.y\n",
    "    def updateCoords(self, xn, yn):\n",
    "        self.age = 0\n",
    "        self.tracks.append([self.x,self.y])\n",
    "        self.x = xn\n",
    "        self.y = yn\n",
    "    def setDone(self):\n",
    "        self.done = True\n",
    "    def timedOut(self):\n",
    "        return self.done\n",
    "    def going_UP(self,mid_start,mid_end):\n",
    "        if len(self.tracks) >= 2:\n",
    "            if self.state == '0':\n",
    "                if self.tracks[-1][1] < mid_end and self.tracks[-2][1] >= mid_end: #cruzo la linea\n",
    "                    state = '1'\n",
    "                    self.dir = 'up'\n",
    "                    return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    def going_DOWN(self,mid_start,mid_end):\n",
    "        if len(self.tracks) >= 2:\n",
    "            if self.state == '0':\n",
    "                if self.tracks[-1][1] > mid_start and self.tracks[-2][1] <= mid_start: #cruzo la linea\n",
    "                    state = '1'\n",
    "                    self.dir = 'down'\n",
    "                    return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    def age_one(self):\n",
    "        self.age += 1\n",
    "        if self.age > self.max_age:\n",
    "            self.done = True\n",
    "        return True\n",
    "class MultiPerson:\n",
    "    def __init__(self, persons, xi, yi):\n",
    "        self.persons = persons\n",
    "        self.x = xi\n",
    "        self.y = yi\n",
    "        self.tracks = []\n",
    "        self.R = randint(0,255)\n",
    "        self.G = randint(0,255)\n",
    "        self.B = randint(0,255)\n",
    "        self.done = False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd373d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1 0.0\n",
      "2 0.001\n",
      "3 596.0\n",
      "4 336.0\n",
      "5 29.97\n",
      "6 808996950.0\n",
      "7 240.0\n",
      "8 0.0\n",
      "9 0.0\n",
      "10 0.0\n",
      "11 0.0\n",
      "12 0.0\n",
      "13 0.0\n",
      "14 0.0\n",
      "15 0.0\n",
      "16 1.0\n",
      "17 0.0\n",
      "18 0.0\n",
      "Area Threshold 667.52\n",
      "Red line y: 268\n",
      "Blue line y: 134\n",
      "ID: 2 crossed going down at Wed May 10 23:45:18 2023\n",
      "ID: 1 crossed going up at Wed May 10 23:45:19 2023\n",
      "ID: 1 crossed going up at Wed May 10 23:45:19 2023\n",
      "ID: 7 crossed going up at Wed May 10 23:45:19 2023\n",
      "ID: 1 crossed going down at Wed May 10 23:45:19 2023\n",
      "ID: 4 crossed going down at Wed May 10 23:45:19 2023\n",
      "ID: 3 crossed going down at Wed May 10 23:45:19 2023\n",
      "ID: 2 crossed going down at Wed May 10 23:45:20 2023\n",
      "ID: 1 crossed going up at Wed May 10 23:45:21 2023\n",
      "ID: 3 crossed going up at Wed May 10 23:45:21 2023\n",
      "ID: 6 crossed going down at Wed May 10 23:45:22 2023\n",
      "ID: 7 crossed going up at Wed May 10 23:45:22 2023\n",
      "ID: 1 crossed going down at Wed May 10 23:45:22 2023\n",
      "ID: 6 crossed going down at Wed May 10 23:45:23 2023\n",
      "ID: 3 crossed going up at Wed May 10 23:45:23 2023\n",
      "ID: 1 crossed going up at Wed May 10 23:45:23 2023\n",
      "ID: 2 crossed going down at Wed May 10 23:45:23 2023\n",
      "ID: 4 crossed going down at Wed May 10 23:45:23 2023\n",
      "ID: 3 crossed going up at Wed May 10 23:45:24 2023\n",
      "ID: 2 crossed going down at Wed May 10 23:45:24 2023\n",
      "ID: 2 crossed going up at Wed May 10 23:45:24 2023\n",
      "ID: 6 crossed going down at Wed May 10 23:45:24 2023\n",
      "ID: 1 crossed going down at Wed May 10 23:45:24 2023\n",
      "ID: 7 crossed going up at Wed May 10 23:45:24 2023\n",
      "ID: 15 crossed going down at Wed May 10 23:45:25 2023\n",
      "ID: 5 crossed going down at Wed May 10 23:45:25 2023\n",
      "ID: 10 crossed going up at Wed May 10 23:45:25 2023\n",
      "ID: 20 crossed going up at Wed May 10 23:45:25 2023\n",
      "ID: 5 crossed going down at Wed May 10 23:45:25 2023\n",
      "ID: 1 crossed going down at Wed May 10 23:45:25 2023\n",
      "ID: 6 crossed going down at Wed May 10 23:45:25 2023\n",
      "ID: 5 crossed going up at Wed May 10 23:45:25 2023\n",
      "ID: 10 crossed going up at Wed May 10 23:45:26 2023\n",
      "ID: 4 crossed going down at Wed May 10 23:45:26 2023\n",
      "ID: 6 crossed going down at Wed May 10 23:45:26 2023\n",
      "ID: 2 crossed going up at Wed May 10 23:45:27 2023\n",
      "ID: 5 crossed going down at Wed May 10 23:45:27 2023\n",
      "ID: 1 crossed going down at Wed May 10 23:45:27 2023\n",
      "ID: 2 crossed going up at Wed May 10 23:45:27 2023\n",
      "ID: 1 crossed going up at Wed May 10 23:45:28 2023\n",
      "ID: 5 crossed going down at Wed May 10 23:45:28 2023\n",
      "\n",
      "ID: 2 crossed going up at Wed May 10 23:45:28 2023\n",
      "\n",
      "ID: 1 crossed going up at Wed May 10 23:45:28 2023\n",
      "ID: 1 crossed going down at Wed May 10 23:45:29 2023\n",
      "ID: 3 crossed going down at Wed May 10 23:45:29 2023\n",
      "ID: 3 crossed going up at Wed May 10 23:45:29 2023\n",
      "ID: 1 crossed going down at Wed May 10 23:45:29 2023\n",
      "EOF\n",
      "UP: 23.133333333333333\n",
      "DOWN: 25.15\n"
     ]
    }
   ],
   "source": [
    "##People counter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "cnt_up   = 0\n",
    "cnt_down = 0\n",
    "count_up = 0\n",
    "count_down = 0\n",
    "state =0\n",
    "\n",
    "#Taking the video input\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\abdul\\Downloads\\stock-footage-skolkovo-russia-april-time-lapse-high-angle-of-various-people-passing-through.webm\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output1.mkv',fourcc, 20.0, (640,480))\n",
    "\n",
    "\n",
    "\n",
    "##cap.set(3,160) #Width\n",
    "##cap.set(4,120) #Height\n",
    "\n",
    "#Print the capture properties to console\n",
    "for i in range(19):\n",
    "    print (i, cap.get(i))\n",
    "\n",
    "w = cap.get(3)\n",
    "h = cap.get(4)\n",
    "frameArea = h*w\n",
    "areaTH = frameArea/300\n",
    "print ('Area Threshold', areaTH)\n",
    "\n",
    "#Lines coordinate for counting\n",
    "line_up = int(2*(h/5))\n",
    "line_down   = int(4*(h/5))\n",
    "\n",
    "up_limit =   int(.5*(h/5))\n",
    "down_limit = int(4.5*(h/5))\n",
    "\n",
    "print (\"Red line y:\",str(line_down))\n",
    "print (\"Blue line y:\", str(line_up))\n",
    "line_down_color = (255,0,0)\n",
    "line_up_color = (0,0,255)\n",
    "\n",
    "pt1 =  [1, line_down];\n",
    "pt2 =  [w, line_down];\n",
    "pts_L1 = np.array([pt1,pt2], np.int32)\n",
    "pts_L1 = pts_L1.reshape((-1,1,2))\n",
    "pt3 =  [0, line_up];\n",
    "pt4 =  [w, line_up];\n",
    "\n",
    "pts_L2 = np.array([pt3,pt4], np.int32)\n",
    "pts_L2 = pts_L2.reshape((-1,1,2))\n",
    "\n",
    "pt5 =  [0, up_limit];\n",
    "pt6 =  [w, up_limit];\n",
    "\n",
    "pts_L3 = np.array([pt5,pt6], np.int32)\n",
    "pts_L3 = pts_L3.reshape((-1,1,2))\n",
    "pt7 =  [0, down_limit];\n",
    "pt8 =  [w, down_limit];\n",
    "pts_L4 = np.array([pt7,pt8], np.int32)\n",
    "pts_L4 = pts_L4.reshape((-1,1,2))\n",
    "\n",
    "#Background Substractor\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows = True)\n",
    "\n",
    "#Structuring elements for morphographic filters\n",
    "kernelOp = np.ones((3,3),np.uint8)\n",
    "kernelOp2 = np.ones((5,5),np.uint8)\n",
    "kernelCl = np.ones((11,11),np.uint8)\n",
    "\n",
    "#Variables\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "persons = []\n",
    "rect_co = []\n",
    "max_p_age = 1\n",
    "pid = 1\n",
    "val = []\n",
    "\n",
    "while(cap.isOpened()):\n",
    "##for image in camera.capture_continuous(rawCapture, format=\"bgr\", use_video_port=True):\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "##    frame = image.array\n",
    "\n",
    "    # for i in persons:\n",
    "    #     print i.age_one() #age every person one frame\n",
    "\n",
    "    \n",
    "    \n",
    "    #Apply background subtraction\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask2 = fgbg.apply(frame)\n",
    "\n",
    "    #Binarization to eliminate shadows\n",
    "    try:\n",
    "        ret,imBin= cv2.threshold(fgmask,200,255,cv2.THRESH_BINARY)\n",
    "        ret,imBin2 = cv2.threshold(fgmask2,200,255,cv2.THRESH_BINARY)\n",
    "        #Opening (erode->dilate) to remove noise.\n",
    "        mask = cv2.morphologyEx(imBin, cv2.MORPH_OPEN, kernelOp)\n",
    "        mask2 = cv2.morphologyEx(imBin2, cv2.MORPH_OPEN, kernelOp)\n",
    "        #Closing (dilate -> erode) to join white regions.\n",
    "        mask =  cv2.morphologyEx(mask , cv2.MORPH_CLOSE, kernelCl)\n",
    "        mask2 = cv2.morphologyEx(mask2, cv2.MORPH_CLOSE, kernelCl)\n",
    "    except:\n",
    "        print('EOF')\n",
    "        print ('UP:',cnt_up+count_up)\n",
    "        print ('DOWN:',cnt_down+count_down)\n",
    "        break\n",
    "    #################\n",
    "    #   CONTOURS   #\n",
    "    #################\n",
    "    \n",
    "    # RETR_EXTERNAL returns only extreme outer flags. All child contours are left behind.\n",
    "    contours0, hierarchy = cv2.findContours(mask2,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours0:\n",
    "        rect = cv2.boundingRect(cnt)\n",
    "        # print rect_co\n",
    "        # if rect[2] > 100: \n",
    "        #     if rect[1]!=0:\n",
    "        #         rect_co.append(rect[1])\n",
    "        #     if len(rect_co)>=2:\n",
    "        #         if (rect_co[-1]-rect_co[-2]) > 0:\n",
    "        #             count_down = rect[2]/60\n",
    "        #             count_up = 0\n",
    "        #             print 'down' ,count_down\n",
    "        #         elif (rect_co[-1]-rect_co[-2]) < 0:\n",
    "        #             count_up =  rect[2]/60\n",
    "        #             count_down = 0\n",
    "        #             print 'up',count_up\n",
    "                \n",
    "        #     continue\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > areaTH:\n",
    "            #################\n",
    "            #   TRACKING    #\n",
    "            #################\n",
    "            \n",
    "            #Missing conditions for multipersons, outputs and screen entries\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            # print 'working'\n",
    "            # print w\n",
    "\n",
    "            new = True\n",
    "            if cy in range(up_limit,down_limit):\n",
    "                for i in persons:\n",
    "                    if abs(cx-i.getX()) <= w and abs(cy-i.getY()) <= h:\n",
    "                        # the object is close to one that has already been detected before\n",
    "                        # print 'update'\n",
    "                        new = False\n",
    "                        i.updateCoords(cx,cy)   #update coordinates in the object and resets age\n",
    "                        if i.going_UP(line_down,line_up) == True:\n",
    "                            if w > 100:\n",
    "                                count_up = w/60\n",
    "                                #cnt_up += count_up\n",
    "                                print ()\n",
    "                            else:    \n",
    "                                cnt_up += 1;\n",
    "                            print (\"ID:\",i.getId(),'crossed going up at',time.strftime(\"%c\"))\n",
    "                        elif i.going_DOWN(line_down,line_up) == True:\n",
    "                            if w > 100:\n",
    "                                count_down = w/60\n",
    "                                #cnt_down += count_down\n",
    "                            else:\n",
    "                                cnt_down += 1;\n",
    "                            print (\"ID:\",i.getId(),'crossed going down at',time.strftime(\"%c\"))\n",
    "                        break\n",
    "                    if i.getState() == '1':\n",
    "                        if i.getDir() == 'down' and i.getY() > down_limit:\n",
    "                            i.setDone()\n",
    "                        elif i.getDir() == 'up' and i.getY() < up_limit:\n",
    "                            i.setDone()\n",
    "                    if i.timedOut():\n",
    "                        #get out of the people list\n",
    "                        index = persons.index(i)\n",
    "                        persons.pop(index)\n",
    "                        del i     #free the memory of i\n",
    "                if new == True:\n",
    "                    p = MyPerson(pid,cx,cy, max_p_age)\n",
    "                    persons.append(p)\n",
    "                    pid += 1    \n",
    "            # new = True\n",
    "            # print cy\n",
    "            # if cy in range(up_limit,down_limit):\n",
    "            #     for i in persons:\n",
    "            #         if abs(cx-i.getX()) <= w and abs(cy-i.getY()) <= h:\n",
    "            #             # the object is close to one that has already been detected before\n",
    "            #             new = False\n",
    "            #             i.updateCoords(cx,cy)\n",
    "            #             val = i.getTracks()   #update coordinates in the object and resets age\n",
    "            #             print val\n",
    "                    \n",
    "            #     # print new  \n",
    "            #     if new == True:\n",
    "            #         p = Person.MyPerson(pid,cx,cy, max_p_age)\n",
    "            #         persons.append(p)\n",
    "            #         pid += 1 \n",
    "            #     # print 'person length',len(persons)     \n",
    "            #     if len(val)>=2:\n",
    "            #         if (val[-1][1]-val[-2][1]) > 0:\n",
    "            #             cnt_down += 1;\n",
    "            #             state='1'\n",
    "            #             getdir = 'down'\n",
    "            #             # print \"ID:\",i.getId(),'crossed going up at',time.strftime(\"%c\")\n",
    "            #         elif (val[-1][1]-val[-2][1]) < 0:\n",
    "            #             cnt_up += 1;\n",
    "            #             state = '1'\n",
    "            #             getdir = 'up'\n",
    "            #             # print \"ID:\",i.getId(),'crossed going down at',time.strftime(\"%c\")\n",
    "            #         val = []    \n",
    "            #         if state == '1':\n",
    "            #                 if getdir == 'down':\n",
    "            #                     done=True\n",
    "            #                 elif getdir == 'up':\n",
    "            #                     done = True\n",
    "            #         if done:\n",
    "            #              #get out of the people list\n",
    "            #             j=persons[0]\n",
    "            #             # print j\n",
    "            #             index = persons.index(j)\n",
    "            #             persons.pop(index)\n",
    "            #             # print \"delete\"\n",
    "            #             del j     #free the memory of i\n",
    "            #################\n",
    "            #   DRAWINGS     #\n",
    "            #################\n",
    "            cv2.circle(frame,(cx,cy), 5, (0,0,255), -1)\n",
    "            img = cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)            \n",
    "            #cv2.drawContours(frame, cnt, -1, (0,255,0), 3)\n",
    "            \n",
    "    #END for cnt in contours0\n",
    "            \n",
    "    #########################\n",
    "    # DRAWING TRAJECTORIES  #\n",
    "    #########################\n",
    "    for i in persons:\n",
    "##        if len(i.getTracks()) >= 2:\n",
    "##            pts = np.array(i.getTracks(), np.int32)\n",
    "##            pts = pts.reshape((-1,1,2))\n",
    "##            frame = cv2.polylines(frame,[pts],False,i.getRGB())\n",
    "##        if i.getId() == 9:\n",
    "##            print str(i.getX()), ',', str(i.getY())\n",
    "        cv2.putText(frame, str(i.getId()),(i.getX(),i.getY()),font,0.3,i.getRGB(),1,cv2.LINE_AA)\n",
    "        \n",
    "    #################\n",
    "    # DISPLAY ON FRAME    #\n",
    "    #################\n",
    "    str_up = 'UP: '+ str(cnt_up+count_up)\n",
    "    str_down = 'DOWN: '+ str(cnt_down+count_down)\n",
    "    \n",
    "    frame = cv2.polylines(frame,[pts_L1],False,line_down_color,thickness=2)\n",
    "    frame = cv2.polylines(frame,[pts_L2],False,line_up_color,thickness=2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    frame = cv2.polylines(frame,[pts_L3],True,(255,255,255),thickness=1)\n",
    "    frame = cv2.polylines(frame,[pts_L4],False,(255,255,255),thickness=1)\n",
    "    cv2.putText(frame, str_up ,(10,40),font,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(frame, str_up ,(10,40),font,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "    cv2.putText(frame, str_down ,(10,90),font,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(frame, str_down ,(10,90),font,0.5,(255,0,0),1,cv2.LINE_AA)\n",
    "   \n",
    "\n",
    "    \n",
    "    out.write(frame)\n",
    "    cv2.imshow('Frame',frame)\n",
    "    #cv2.imshow('Mask',mask)    \n",
    "    \n",
    "    #Press ESC to exit\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "#END while(cap.isOpened())\n",
    "    \n",
    "#################\n",
    "#   CLOSING    #\n",
    "#################\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f302d640",
   "metadata": {},
   "source": [
    "# 3rd Working Project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94144b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Tracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 35:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "#                    print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d678f692",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4073684311.py, line 68)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [6], line 68\u001b[1;36m\u001b[0m\n\u001b[1;33m    result1 = cv2.pointPolygonTest(np.array(area2,np.int32),((x4,y4)),False)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "\n",
    "model=YOLO('yolov8s.pt')\n",
    "\n",
    "\n",
    "area1=[(616, 235),(730, 250),(727, 280),(606, 265)]\n",
    "\n",
    "area2=[(567, 274),(739, 302),(736, 315),(556, 293)]\n",
    "\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE :  \n",
    "        colorsBGR = [x, y]\n",
    "        print(colorsBGR)\n",
    "        \n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "cap=cv2.VideoCapture(r'C:\\Users\\abdul\\Downloads\\Commercial CCTV at a Bar in Chapel Allerton, Leeds, LS7.mp4')\n",
    "\n",
    "\n",
    "my_file = open(\"coco.txt\", \"r\")\n",
    "data = my_file.read()\n",
    "class_list = data.split(\"\\n\") \n",
    "#print(class_list)\n",
    "\n",
    "count=0\n",
    "\n",
    "tracker = Tracker()\n",
    "people = {}\n",
    "\n",
    "while True:    \n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    if count % 2 != 0:\n",
    "        continue\n",
    "    frame=cv2.resize(frame,(1020,500))\n",
    "#    frame=cv2.flip(frame,1)\n",
    "    results=model.predict(frame)\n",
    " #   print(results)\n",
    "    a=results[0].boxes.boxes\n",
    "    px=pd.DataFrame(a).astype(\"float\")\n",
    "#    print(px)\n",
    "    list1=[]\n",
    "             \n",
    "    for index,row in px.iterrows():\n",
    "#        print(row)\n",
    " \n",
    "        x1=int(row[0])\n",
    "        y1=int(row[1])\n",
    "        x2=int(row[2])\n",
    "        y2=int(row[3])\n",
    "        d=int(row[5])\n",
    "        c=class_list[d]\n",
    "        if 'person' in c:\n",
    "            list1.append([x1, y1, x2, y2])\n",
    "    bbox_id = tracker.update(list1)\n",
    "    for bbox in bbox_id:\n",
    "        x3, y3, x4, y4, id = bbox\n",
    "        results = cv2.pointPolygonTest(np.array(area2,np.int32),((x4,y4)),False) \n",
    "                result1 = cv2.pointPolygonTest(np.array(area2,np.int32),((x4,y4)),False) \n",
    "              \n",
    "                    cv2.rectangle(frame,(x3,y3),(x4,y4),(0,255,0),2)\n",
    "                    cv2.circle(frame,(x4,y4), 5, (255,0,255), -1)\n",
    "                    cv2.putText(frame,str(id),(x3,y3),cv2.FONT_HERSHEY_COMPLEX,0.5,(255,255,255),1)\n",
    "\n",
    "            \n",
    "        \n",
    "    cv2.polylines(frame,[np.array(area1,np.int32)],True,(255,0,0),2)\n",
    "    cv2.putText(frame,str('1'),(504,471),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "\n",
    "    cv2.polylines(frame,[np.array(area2,np.int32)],True,(255,0,0),2)\n",
    "    cv2.putText(frame,str('2'),(466,485),cv2.FONT_HERSHEY_COMPLEX,(0.5),(0,0,0),1)\n",
    "    print(people)\n",
    "\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(1)&0xFF==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1542645",
   "metadata": {},
   "source": [
    "# 4th project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c4dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WORKING SPECS:\n",
    "# OpenCV_3.1.0\n",
    "# Python_2.7.12\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import colorsys\n",
    "import collections\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# ================== DEFINE CLASS ====================\n",
    "# ====================================================\n",
    "\n",
    "class Position(object):\n",
    "    def __init__(self, _x, _y, _w, _h):\n",
    "        self.x = _x\n",
    "        self.y = _y\n",
    "        self.w = _w\n",
    "        self.h = _h\n",
    "\n",
    "    def x(self):\n",
    "        return self.x\n",
    "\n",
    "    def y(self):\n",
    "        return self.y\n",
    "\n",
    "    def w(self):\n",
    "        return self.w\n",
    "\n",
    "    def h(self):\n",
    "        return self.h\n",
    "\n",
    "class People(object):\n",
    "    def __init__(self, _x, _y, _w, _h, _roi, _hue):\n",
    "        # Position\n",
    "        self.x = _x\n",
    "        self.y = _y\n",
    "        self.w = _w\n",
    "        self.h = _h\n",
    "        self.roi = _roi\n",
    "\n",
    "        # Display of the contour while tracking\n",
    "        self.hue = _hue\n",
    "        self.color = hsv2rgb(self.hue%1, 1, 1)\n",
    "\n",
    "        # Motion Descriptors\n",
    "        self.center = [_x + _w/2, _y + _h/2]\n",
    "        self.isIn = checkPosition(boundaryPt1, boundaryPt2, self.center, inCriterion)\n",
    "        self.isInChangeFrameCount = toleranceCountIOStatus\n",
    "        self.speed = [0,0]\n",
    "        self.missingCount = 0\n",
    "\n",
    "        # ROI - Region of Interest\n",
    "        self.maxRoi = _roi\n",
    "        self.roi = _roi\n",
    "\n",
    "    def x(self):\n",
    "        return self.x\n",
    "\n",
    "    def y(self):\n",
    "        return self.y\n",
    "\n",
    "    def w(self):\n",
    "        return self.w\n",
    "\n",
    "    def h(self):\n",
    "        return self.h\n",
    "\n",
    "    def roi(self):\n",
    "        return self.roi\n",
    "\n",
    "    def color(self):\n",
    "        return self.color\n",
    "\n",
    "    def center(self):\n",
    "        return self.center\n",
    "\n",
    "    def maxRoi(self):\n",
    "        return self.maxRoi\n",
    "\n",
    "    def isIn(self):\n",
    "        return self.isIn\n",
    "\n",
    "    def speed(self):\n",
    "        return self.speed\n",
    "\n",
    "    def missingCount(self):\n",
    "        return self.missingCount\n",
    "\n",
    "    def isInChangeFrameCount(self):\n",
    "        return self.isInChangeFrameCount\n",
    "\n",
    "    def set(self, name, value):\n",
    "        if name == \"x\":\n",
    "            self.x = value\n",
    "        elif name == \"y\":\n",
    "            self.y = value\n",
    "        elif name == \"w\":\n",
    "            self.w = value\n",
    "        elif name == \"h\":\n",
    "            self.h = value\n",
    "        elif name == \"center\":\n",
    "            self.center = value\n",
    "        elif name == \"roi\":\n",
    "            self.roi = value\n",
    "            # Automatically update maxRoi as roi is updated\n",
    "            if self.roi.shape[0]*self.roi.shape[1] > self.maxRoi.shape[0]*self.maxRoi.shape[1]:\n",
    "                self.maxRoi = self.roi\n",
    "        elif name == \"speed\":\n",
    "            self.speed = value\n",
    "        elif name == \"missingCount\":\n",
    "            self.missingCount = value\n",
    "        elif name == \"isIn\":\n",
    "            self.isIn = value\n",
    "        elif name == \"isInChangeFrameCount\":\n",
    "            self.isInChangeFrameCount = value\n",
    "        else:\n",
    "            return\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# ===================== FUNCTION =====================\n",
    "# ====================================================\n",
    "\n",
    "def averageSize():\n",
    "    sum = 0\n",
    "    for i in humanSizeSample:\n",
    "        sum +=i\n",
    "    return sum/sampleSize\n",
    "\n",
    "\n",
    "# Only care about top and bottom\n",
    "def checkTouchVSide(x, y, w, h, maxW, maxH, tolerance):\n",
    "    if x <= 0:\n",
    "        return True\n",
    "    elif y - tolerance <= 0:\n",
    "        return True\n",
    "    elif x + w >= maxW:\n",
    "        return True\n",
    "    elif y + h + tolerance >= maxH:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def getExteriorRect(pts):\n",
    "    xArray = []\n",
    "    yArray = []\n",
    "    for pt in pts:\n",
    "        xArray.append(pt[0])\n",
    "        yArray.append(pt[1])\n",
    "    xArray = sorted(xArray)\n",
    "    yArray = sorted(yArray)\n",
    "    return (xArray[0], yArray[0], xArray[3] - xArray[0], yArray[3] - yArray[0])\n",
    "\n",
    "\n",
    "def hsv2rgb(h, s, v):\n",
    "    return tuple(i * 255 for i in colorsys.hsv_to_rgb(h, s, v))\n",
    "\n",
    "\n",
    "def checkPosition(boundaryPt1, boundaryPt2, currPos, inCriterion):\n",
    "    m = (boundaryPt2[1] - boundaryPt1[1])/(boundaryPt2[0] - boundaryPt1[0])\n",
    "    c = boundaryPt2[1] - m*boundaryPt2[0]\n",
    "    if inCriterion == \"<\":\n",
    "        if currPos[0] * m + c < currPos[1]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif inCriterion == \">\":\n",
    "        if currPos[0] * m + c > currPos[1]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# ====================================================\n",
    "# ================== VIDEO SOURCE ====================\n",
    "# ====================================================\n",
    "\n",
    "srcTest = 'peopleCounter.avi'\n",
    "srcWebcam = 0\n",
    "srcMain = '' # live source here\n",
    "cap = cv2.VideoCapture(srcTest)  # Open video file\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# ================== PRE-CONFIG ======================\n",
    "# ====================================================\n",
    "\n",
    "minArea = 500  # default min area to be considered person\n",
    "maxArea = 4000  # default max area to be considered person\n",
    "noFrameToCollectSample = 100\n",
    "toleranceRange = 50  # use for error calculation\n",
    "toleranceCount = 10  # maximum number of frame an object need to present in order to be accepted\n",
    "toleranceCountIOStatus = 3  # minimum number of frame between In/Out Status change -> prevent playing with the system\n",
    "startHue = 0  # In HSV this is RED\n",
    "hueIncrementValue = 0.1  # increment color every time to differentiate between different people\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# ====================== SETUP =======================\n",
    "# ====================================================\n",
    "\n",
    "# fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold = 16, detectShadows=True)\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n",
    "sampleSize = 100\n",
    "humanSizeSample = collections.deque(maxlen=sampleSize)\n",
    "\n",
    "midHeight = int(cap.get(4) / 2)\n",
    "maxWidth = cap.get(3)\n",
    "maxHeight = cap.get(4)\n",
    "\n",
    "inCriterion = \"<\"\n",
    "boundaryPt1 = [0, midHeight-100]\n",
    "boundaryPt2 = [maxWidth, midHeight]\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# ====================== MAIN ========================\n",
    "# ====================================================\n",
    "\n",
    "# Passage Control\n",
    "allowPassage = True\n",
    "peopleViolationIn = 0\n",
    "peopleViolationOut = 0\n",
    "switch = '0 : PASS \\n1 : STOP'\n",
    "\n",
    "# Controller\n",
    "cv2.namedWindow('config')\n",
    "cv2.createTrackbar(switch, 'config', 0, 1, nothing)\n",
    "\n",
    "# Initializa Other Variable\n",
    "averageArea = 0.000  # for calculation of min/max size for contour detected\n",
    "peopleIn = 0  # number of people going up\n",
    "peopleOut = 0  # number of people going up\n",
    "frameCounter = 0\n",
    "maskT = None\n",
    "passImage = None\n",
    "detectedPeople = []\n",
    "detectedContours = []\n",
    "\n",
    "# take first frame of the video\n",
    "_ , pFrame = cap.read()\n",
    "\n",
    "while (cap.isOpened()):\n",
    "\n",
    "    # Check Passage Status\n",
    "    status = cv2.getTrackbarPos(switch, 'config')\n",
    "    if status == 0:\n",
    "        allowPassage = True\n",
    "    else:\n",
    "        allowPassage = False\n",
    "\n",
    "    # RE-Initialize\n",
    "    frameInfo = np.zeros((400, 500, 3), np.uint8)\n",
    "    averageArea = averageSize()\n",
    "    ret, frame = cap.read()  # read a frame\n",
    "    frameForView = frame.copy()\n",
    "\n",
    "    # Clean Frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    fgmask = fgbg.apply(gray)\n",
    "    blur = cv2.medianBlur(fgmask, 5)\n",
    "    thresh = cv2.threshold(blur, 127, 255, cv2.THRESH_BINARY)[1]  # shadow of MOG@ is grey = 127\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)  # fill any small holes\n",
    "    opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel)  # remove noise\n",
    "    contours = cv2.findContours(opening.copy(), cv2.RETR_EXTERNAL,\n",
    "                                 cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "\n",
    "    mask_opening = cv2.inRange(opening, np.array([0]), np.array([128]))\n",
    "    noBg = cv2.bitwise_and(frame, frame, mask=mask_opening)\n",
    "\n",
    "    # Process Contours\n",
    "    for c in contours:\n",
    "        # Filter Contour By Size\n",
    "        if len(humanSizeSample) < 100:\n",
    "            if cv2.contourArea(c) < minArea or cv2.contourArea(c) > maxArea:\n",
    "                continue\n",
    "            else:\n",
    "                humanSizeSample.append(cv2.contourArea(c))\n",
    "        else:\n",
    "            if cv2.contourArea(c) < averageArea/2 or cv2.contourArea(c) > averageArea*3:\n",
    "                continue\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        detectedContours.append(Position(x, y, w, h))\n",
    "\n",
    "    # Process Detected People\n",
    "    if len(detectedPeople) != 0:\n",
    "        for people in detectedPeople:\n",
    "\n",
    "            # Setup Meanshift/Camshift for Tracking\n",
    "            track_window = (people.x, people.y, people.w, people.h)\n",
    "            hsv_roi = pOpening[people.y:people.y + people.h, people.x:people.x + people.w]\n",
    "            mask = cv2.inRange(hsv_roi, np.array(128), np.array(256))\n",
    "            roi_hist = cv2.calcHist([hsv_roi], [0], mask, [100], [0, 256])\n",
    "            cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "            term_criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 1, 1)  # Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
    "            dst = cv2.calcBackProject([opening], [0], roi_hist, [0, 256], 1)\n",
    "            ret, track_window = cv2.CamShift(dst, track_window, term_criteria)\n",
    "\n",
    "            # Process POST Tracking\n",
    "            pts = cv2.boxPoints(ret)\n",
    "            pts = np.int0(pts)\n",
    "            img2 = cv2.polylines(frameForView, [pts], True, people.color, 2)\n",
    "            pos = sum(pts)/len(pts)\n",
    "            isFound = False\n",
    "            for dC in detectedContours:\n",
    "                if dC.x - toleranceRange < pos[0] < dC.x + dC.w + toleranceRange \\\n",
    "                        and dC.y - toleranceRange < pos[1] < dC.y + dC.h + toleranceRange:\n",
    "                    people.set(\"x\", dC.x)\n",
    "                    people.set(\"y\", dC.y)\n",
    "                    people.set(\"w\", dC.w)\n",
    "                    people.set(\"h\", dC.h)\n",
    "                    people.set(\"speed\", pos - people.center)\n",
    "                    people.set(\"center\", pos)\n",
    "                    people.set(\"missingCount\", 0)\n",
    "                    detectedContours.remove(dC)\n",
    "                    isFound = True\n",
    "\n",
    "                    tR = getExteriorRect(pts)\n",
    "                    people.set(\"roi\", frame[tR[1]:tR[1]+tR[3], tR[0]:tR[0]+tR[2]])\n",
    "\n",
    "                    # Process Continuous Tracking\n",
    "                    prevInStatus = people.isIn\n",
    "                    currInStatus = checkPosition(boundaryPt1, boundaryPt2, people.center, inCriterion)\n",
    "                    people.isIn = currInStatus\n",
    "\n",
    "                    # Check In/Out Status Change\n",
    "                    if prevInStatus != currInStatus and people.isInChangeFrameCount >= toleranceCountIOStatus:\n",
    "                        if not allowPassage:\n",
    "                            passImage = people.roi\n",
    "                        people.set(\"isInChangeFrameCount\", 0)\n",
    "                        if currInStatus:\n",
    "                            peopleIn += 1\n",
    "                            if not allowPassage:\n",
    "                                peopleViolationIn += 1\n",
    "                        else:\n",
    "                            peopleOut += 1\n",
    "                            if not allowPassage:\n",
    "                                peopleViolationOut += 1\n",
    "                    else:\n",
    "                        people.set(\"isInChangeFrameCount\", people.isInChangeFrameCount + 1)\n",
    "\n",
    "            # Process DIS-continuous Tracking\n",
    "            if not isFound:\n",
    "                if people.missingCount > toleranceCount:\n",
    "                    detectedPeople.remove(people)\n",
    "                else:\n",
    "                    if checkTouchVSide(people.x + people.speed[0], people.y + people.speed[1], people.w,\n",
    "                                       people.h, maxWidth, maxHeight, toleranceRange):\n",
    "                        detectedPeople.remove(people)\n",
    "                    else:\n",
    "                        people.set(\"missingCount\", people.missingCount+1)\n",
    "                        people.set(\"x\", people.x + people.speed[0])\n",
    "                        people.set(\"y\", people.y + people.speed[1])\n",
    "                        people.set(\"center\", people.center + people.speed)\n",
    "\n",
    "    # Check New People\n",
    "    for dC in detectedContours:\n",
    "        if checkTouchVSide(dC.x, dC.y, dC.w, dC.h, maxWidth, maxHeight, toleranceRange):\n",
    "            startHue += hueIncrementValue\n",
    "            detectedPeople.append(People(dC.x, dC.y, dC.w, dC.h, frame[dC.y:dC.y+dC.h, dC.x:dC.x+dC.w], startHue))\n",
    "\n",
    "    # RE-set\n",
    "    detectedContours = []\n",
    "    pFrame = frame\n",
    "    pNoBg = noBg\n",
    "    pOpening = opening\n",
    "    frameCounter += 1\n",
    "\n",
    "    # Output\n",
    "    try:\n",
    "        # Setup Stats\n",
    "        textNoOfPeople = \"People: \" + str(len(detectedPeople))\n",
    "        textNoIn = \"In: \" + str(peopleIn)\n",
    "        textNoOut = \"Out: \" + str(peopleOut)\n",
    "        textNoViolationIn = \"In: \" + str(peopleViolationIn)\n",
    "        textNoViolationOut = \"Out: \" + str(peopleViolationOut)\n",
    "\n",
    "        if allowPassage:\n",
    "            cv2.line(frameForView, (long(boundaryPt1[0]), long(boundaryPt1[1])),\n",
    "                     (long(boundaryPt2[0]), long(boundaryPt2[1])), (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.line(frameForView, (long(boundaryPt1[0]), long(boundaryPt1[1])),\n",
    "                     (long(boundaryPt2[0]), long(boundaryPt2[1])), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw Infos\n",
    "        cv2.putText(frameInfo, textNoOfPeople, (30, 40), cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    , 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frameInfo, textNoIn, (30, 80), cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    , 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frameInfo, textNoOut, (30, 120), cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    , 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.line(frameInfo, (0, 160), (640, 160), (255, 255, 255), 1)\n",
    "        cv2.putText(frameInfo, \"VIOLATION\", (30, 200), cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    , 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frameInfo, textNoViolationIn, (30, 240), cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    , 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frameInfo, textNoViolationOut, (30, 280), cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    , 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Display\n",
    "        cv2.imshow('FrameForView', frameForView)\n",
    "        # cv2.imshow('Frame', frame)\n",
    "        if passImage != None:\n",
    "            cv2.imshow('Violators', passImage)\n",
    "        cv2.imshow('config', frameInfo)\n",
    "\n",
    "    except:\n",
    "        print('EOF')\n",
    "        break\n",
    "\n",
    "    # Abort and exit with 'Q' or ESC\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    # else:\n",
    "    #     cv2.imwrite(chr(k) + \".jpg\", frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f61596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ac4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
